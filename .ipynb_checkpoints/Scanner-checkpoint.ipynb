{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScanError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, _type, lexeme, literal=None):\n",
    "        self.type = _type\n",
    "        self.lexeme = lexeme\n",
    "        self.literal = literal\n",
    "        \n",
    "    def __repr__(self):\n",
    "        string_list = [\n",
    "            \"'type': \" + str(self.type), \n",
    "            \"'lexeme': \" + str(self.lexeme), \n",
    "            \"'literal': \" + str(self.literal)\n",
    "        ]\n",
    "        return '{' + ', '.join(string_list) + '}'\n",
    "\n",
    "    def __str__(self):\n",
    "        string_list = [\n",
    "            \"type= \" + str(self.type),\n",
    "            \"lexeme= \" + str(self.lexeme), \n",
    "            \"literal= \" + str(self.literal)\n",
    "        ]\n",
    "        return 'Token(' + ', '.join(string_list) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scanner:\n",
    "    \"\"\"Scan formula string and returns Tokens\"\"\"\n",
    "    \n",
    "    def __init__(self, code):\n",
    "        self.code = code\n",
    "        self.start = 0\n",
    "        self.current = 0\n",
    "        self.tokens = []\n",
    "        self.keywords = {}\n",
    "        \n",
    "        if not len(self.code):\n",
    "            raise ScanError(\"'code' is a string of length 0.\")\n",
    "            \n",
    "    def is_at_end(self):\n",
    "        return self.current >= len(self.code)\n",
    "    \n",
    "    def advance(self):\n",
    "        self.current += 1\n",
    "        return self.code[self.current - 1]\n",
    "    \n",
    "    def peek(self):\n",
    "        if self.is_at_end():\n",
    "            return ''\n",
    "        return self.code[self.current]\n",
    "    \n",
    "    def peek_next(self):\n",
    "        if self.current + 1 >= len(self.code): # o len(self.code) + 1\n",
    "            return ''\n",
    "        return self.code[self.current + 1]\n",
    "    \n",
    "    def match(self, expected):\n",
    "        if self.is_at_end():\n",
    "            return False\n",
    "        if self.code[self.current] != expected:\n",
    "            return False\n",
    "        self.current += 1\n",
    "        return True\n",
    "    \n",
    "    def scan_token(self):\n",
    "        char = self.advance()\n",
    "        if char == '(':\n",
    "            self.add_token('LEFT_PAREN')\n",
    "        elif char == ')':\n",
    "            self.add_token('RIGHT_PAREN')\n",
    "        elif char == '[':\n",
    "            self.add_token('LEFT_BRACKET')\n",
    "        elif char == ']':\n",
    "            self.add_token('RIGHT_BRACKET')\n",
    "        elif char == '{':\n",
    "            self.add_token('LEFT_BRACE')\n",
    "        elif char == '}':\n",
    "            self.add_token('RIGHT_BRACE')\n",
    "        elif char == ',':\n",
    "            self.add_token('COMMA')\n",
    "        elif char == '.':\n",
    "            self.add_token('PERIOD')\n",
    "        elif char == '+':\n",
    "            self.add_token('PLUS')\n",
    "        elif char == '-':\n",
    "            self.add_token('MINUS')\n",
    "        elif char == '/':\n",
    "            self.add_token('SLASH')\n",
    "        elif char == '*':\n",
    "            if self.match('*'):\n",
    "                self.add_token('STAR_STAR')\n",
    "            else:\n",
    "                self.add_token('STAR')\n",
    "        elif char == '~':\n",
    "            self.add_token('TILDE')\n",
    "        elif char == ':':\n",
    "            self.add_token('COLON')\n",
    "        elif char == '|':\n",
    "            self.add_token('PIPE')\n",
    "        elif char in [' ', '\\n', '\\t', '\\r']:\n",
    "            return None\n",
    "        elif char.isdigit():\n",
    "            self.number()\n",
    "        elif char.isalpha():\n",
    "            self.identifier()\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected character: \" + str(char))\n",
    "    \n",
    "    def scan_tokens(self):\n",
    "        while not self.is_at_end():\n",
    "            self.start = self.current\n",
    "            self.scan_token()\n",
    "        self.tokens.append(Token('EOF', ''))\n",
    "        return self.tokens\n",
    "    \n",
    "    def number(self):\n",
    "        is_float = False\n",
    "        \n",
    "        while self.peek().isdigit():\n",
    "            self.advance()\n",
    "            \n",
    "        # Look for fractional part, if present    \n",
    "        if self.peek() == \".\" and self.peek_next().isdigit():\n",
    "            is_float = True\n",
    "            # Consume the dot\n",
    "            self.advance()\n",
    "            # Keep consuming numbers, if present\n",
    "            while self.peek().isdigit():\n",
    "                self.advance()\n",
    "        \n",
    "        if is_float:\n",
    "            token = float(self.code[self.start:self.current])\n",
    "        else:\n",
    "            token = int(self.code[self.start:self.current])\n",
    "            \n",
    "        self.add_token('NUMBER', token)\n",
    "    \n",
    "    def identifier(self):\n",
    "        while self.peek().isalnum():\n",
    "            self.advance()\n",
    "        # Check if the identifier is a reserved word\n",
    "        identifier = self.code[self.start:self.current]\n",
    "        if identifier in self.keywords.keys():\n",
    "            _type = self.keywords[identifier]\n",
    "        else:\n",
    "            _type = 'IDENTIFIER'\n",
    "        self.add_token(_type)\n",
    "            \n",
    "    def add_token(self, _type, literal=None):\n",
    "        # Only literals have \"literal != None\"\n",
    "        source = self.code[self.start:self.current]\n",
    "        self.tokens.append(Token(_type, source, literal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': IDENTIFIER, 'lexeme': x, 'literal': None},\n",
       " {'type': PLUS, 'lexeme': +, 'literal': None},\n",
       " {'type': IDENTIFIER, 'lexeme': y, 'literal': None},\n",
       " {'type': EOF, 'lexeme': , 'literal': None}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scanner('x + y').scan_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': IDENTIFIER, 'lexeme': y, 'literal': None},\n",
       " {'type': TILDE, 'lexeme': ~, 'literal': None},\n",
       " {'type': IDENTIFIER, 'lexeme': a, 'literal': None},\n",
       " {'type': PLUS, 'lexeme': +, 'literal': None},\n",
       " {'type': IDENTIFIER, 'lexeme': b, 'literal': None},\n",
       " {'type': PLUS, 'lexeme': +, 'literal': None},\n",
       " {'type': IDENTIFIER, 'lexeme': c, 'literal': None},\n",
       " {'type': EOF, 'lexeme': , 'literal': None}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scanner('y ~ a + b + c').scan_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': IDENTIFIER, 'lexeme': y, 'literal': None},\n",
       " {'type': TILDE, 'lexeme': ~, 'literal': None},\n",
       " {'type': NUMBER, 'lexeme': 2, 'literal': 2},\n",
       " {'type': STAR, 'lexeme': *, 'literal': None},\n",
       " {'type': IDENTIFIER, 'lexeme': x, 'literal': None},\n",
       " {'type': EOF, 'lexeme': , 'literal': None}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scanner('y ~ 2*x').scan_tokens()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "formulas",
   "language": "python",
   "name": "formulas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
